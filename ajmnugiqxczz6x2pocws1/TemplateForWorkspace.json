{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "ajmnugiqxczz6x2pocws1"
		},
		"LSV2_SqlServer1_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'LSV2_SqlServer1'"
		},
		"TripFaresSynapseAnalyticsLinkedService_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'TripFaresSynapseAnalyticsLinkedService'"
		},
		"ls_adls_gen2_rawdata_accountKey": {
			"type": "secureString",
			"metadata": "Secure string for 'accountKey' of 'ls_adls_gen2_rawdata'"
		},
		"ls_gen2AzureDataLakeStorage1_accountKey": {
			"type": "secureString",
			"metadata": "Secure string for 'accountKey' of 'ls_gen2AzureDataLakeStorage1'"
		},
		"HttpServerTripDataLinkedService_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://raw.githubusercontent.com/Azure/Test-Drive-Azure-Synapse-with-a-1-click-POC/main/tripDataAndFaresCSV/trip-data.csv"
		},
		"HttpServerTripFareDataLinkedService_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://raw.githubusercontent.com/Azure/Test-Drive-Azure-Synapse-with-a-1-click-POC/main/tripDataAndFaresCSV/fares-data.csv"
		},
		"TripFaresDataLakeStorageLinkedService_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "@{concat('https://',linkedService().datalakeAccountName,'.dfs.core.windows.net')}"
		},
		"keyVaultLinkedservice_properties_typeProperties_baseUrl": {
			"type": "string",
			"defaultValue": "@{concat('https://',linkedService().keyVaultName,'.vault.azure.net/')}"
		},
		"ls_adls_gen2_rawdata_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://ajmnugiqxczz6x2poc.dfs.core.windows.net"
		},
		"ls_gen2AzureDataLakeStorage1_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://ajmnugiqxczz6x2poc.dfs.core.windows.net"
		},
		"nyc_tlc_yellow_sasUri": {
			"type": "secureString",
			"metadata": "Secure string for 'sasUri' of 'nyc_tlc_yellow'"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/NotebookPipeline1')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Notebook1",
						"type": "SynapseNotebook",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "Data Exploration and ML Modeling - NYC taxi predict using Spark MLlib",
								"type": "NotebookReference"
							},
							"snapshot": true
						}
					}
				],
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/notebooks/Data Exploration and ML Modeling - NYC taxi predict using Spark MLlib')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PipelineCopyOnPrem')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Copy_from_onprem_sql_server",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [
							{
								"name": "Source",
								"value": "dbo.trip-data"
							},
							{
								"name": "Destination",
								"value": "independent//"
							}
						],
						"typeProperties": {
							"source": {
								"type": "SqlServerSource",
								"partitionOption": "None"
							},
							"sink": {
								"type": "DelimitedTextSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								},
								"formatSettings": {
									"type": "DelimitedTextWriteSettings",
									"quoteAllText": true,
									"fileExtension": ".csv"
								}
							},
							"enableStaging": false,
							"validateDataConsistency": false,
							"translator": {
								"type": "TabularTranslator",
								"mappings": [
									{
										"source": {
											"name": "medallion",
											"type": "String"
										},
										"sink": {
											"name": "medallion",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "hack_license",
											"type": "String"
										},
										"sink": {
											"name": "hack_license",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "vendor_id",
											"type": "String"
										},
										"sink": {
											"name": "vendor_id",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "rate_code",
											"type": "String"
										},
										"sink": {
											"name": "rate_code",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "store_and_fwd_flag",
											"type": "String"
										},
										"sink": {
											"name": "store_and_fwd_flag",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "pickup_datetime",
											"type": "DateTime"
										},
										"sink": {
											"name": "pickup_datetime",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "dropoff_datetime",
											"type": "DateTime"
										},
										"sink": {
											"name": "dropoff_datetime",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "passenger_count",
											"type": "String"
										},
										"sink": {
											"name": "passenger_count",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "trip_time_in_secs",
											"type": "String"
										},
										"sink": {
											"name": "trip_time_in_secs",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "trip_distance",
											"type": "Double"
										},
										"sink": {
											"name": "trip_distance",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "pickup_longitude",
											"type": "String"
										},
										"sink": {
											"name": "pickup_longitude",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "pickup_latitude",
											"type": "String"
										},
										"sink": {
											"name": "pickup_latitude",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "dropoff_longitude",
											"type": "String"
										},
										"sink": {
											"name": "dropoff_longitude",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "dropoff_latitude",
											"type": "String"
										},
										"sink": {
											"name": "dropoff_latitude",
											"type": "String"
										}
									}
								]
							}
						},
						"inputs": [
							{
								"referenceName": "SourceDataset_zcj",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "DestinationDataset_zcj",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/SourceDataset_zcj')]",
				"[concat(variables('workspaceId'), '/datasets/DestinationDataset_zcj')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TripFaresDataPipeline')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "IngestTripDataIntoADLS",
						"description": "Copies the trip data csv file from the git repo and loads it into the ADLS.",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.00:10:00",
							"retry": 3,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "HttpReadSettings",
									"requestMethod": "GET"
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"sink": {
								"type": "DelimitedTextSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								},
								"formatSettings": {
									"type": "DelimitedTextWriteSettings",
									"quoteAllText": true,
									"fileExtension": ".txt"
								}
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "tripsDataSource",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "tripDataSink",
								"type": "DatasetReference",
								"parameters": {
									"datalakeAccountName": {
										"value": "@pipeline().parameters.datalakeAccountName",
										"type": "Expression"
									},
									"keyVaultName": {
										"value": "@pipeline().parameters.KeyVaultName",
										"type": "Expression"
									}
								}
							}
						]
					},
					{
						"name": "IngestTripFaresDataIntoADLS",
						"description": "Copies the trip fare data csv file from the git repo and loads it into the ADLS.",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.00:10:00",
							"retry": 3,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "HttpReadSettings",
									"requestMethod": "GET"
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"sink": {
								"type": "DelimitedTextSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								},
								"formatSettings": {
									"type": "DelimitedTextWriteSettings",
									"quoteAllText": true,
									"fileExtension": ".txt"
								}
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "faresDataSource",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "faresDataSink",
								"type": "DatasetReference",
								"parameters": {
									"keyVaultName": {
										"value": "@pipeline().parameters.KeyVaultName",
										"type": "Expression"
									},
									"datalakeAccountName": {
										"value": "@pipeline().parameters.datalakeAccountName",
										"type": "Expression"
									}
								}
							}
						]
					},
					{
						"name": "JoinAndAggregateData",
						"description": "Reads the raw data from both CSV files inside the ADLS, performs the desired transformations (inner join and aggregation) and writes the transformed data into the synapse SQL pool.",
						"type": "ExecuteDataFlow",
						"dependsOn": [
							{
								"activity": "Create Schema If Does Not Exists",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.00:30:00",
							"retry": 3,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "tripFaresDataTransformations",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"TripDataCSV": {
										"datalakeAccountName": {
											"value": "@pipeline().parameters.datalakeAccountName",
											"type": "Expression"
										},
										"keyVaultName": {
											"value": "@pipeline().parameters.KeyVaultName",
											"type": "Expression"
										}
									},
									"FaresDataCSV": {
										"keyVaultName": {
											"value": "@pipeline().parameters.KeyVaultName",
											"type": "Expression"
										},
										"datalakeAccountName": {
											"value": "@pipeline().parameters.datalakeAccountName",
											"type": "Expression"
										}
									},
									"SynapseAnalyticsSink": {
										"SchemaName": {
											"value": "@pipeline().parameters.SchemaName",
											"type": "Expression"
										},
										"SynapseWorkspaceName": {
											"value": "@pipeline().parameters.SynapseWorkspaceName",
											"type": "Expression"
										},
										"SQLDedicatedPoolName": {
											"value": "@pipeline().parameters.SQLDedicatedPoolName",
											"type": "Expression"
										},
										"keyVaultName": {
											"value": "@pipeline().parameters.KeyVaultName",
											"type": "Expression"
										},
										"SQLLoginUsername": {
											"value": "@pipeline().parameters.SQLLoginUsername",
											"type": "Expression"
										}
									}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					},
					{
						"name": "Create Schema If Does Not Exists",
						"description": "Creates the schema inside the SQL dedicated pool. Shema name comes from the pipeline parameter 'SchemaName'.",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "IngestTripDataIntoADLS",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "IngestTripFaresDataIntoADLS",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.00:05:00",
							"retry": 3,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlDWSource",
								"sqlReaderQuery": {
									"value": "IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = '@{pipeline().parameters.SchemaName}')\nBEGIN\nEXEC('CREATE SCHEMA @{pipeline().parameters.SchemaName}')\nselect Count(*) from sys.symmetric_keys;\nEND\nELSE\nBEGIN\n    select Count(*) from sys.symmetric_keys;\nEND",
									"type": "Expression"
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "azureSynapseAnalyticsSchema",
								"type": "DatasetReference",
								"parameters": {
									"SynapseWorkspaceName": {
										"value": "@pipeline().parameters.SynapseWorkspaceName",
										"type": "Expression"
									},
									"SQLDedicatedPoolName": {
										"value": "@pipeline().parameters.SQLDedicatedPoolName",
										"type": "Expression"
									},
									"keyVaultName": {
										"value": "@pipeline().parameters.KeyVaultName",
										"type": "Expression"
									},
									"SQLLoginUsername": {
										"value": "@pipeline().parameters.SQLLoginUsername",
										"type": "Expression"
									}
								}
							},
							"firstRowOnly": false
						}
					}
				],
				"parameters": {
					"SchemaName": {
						"type": "string",
						"defaultValue": "tripFares"
					},
					"SynapseWorkspaceName": {
						"type": "string",
						"defaultValue": "ajmnugiqxczz6x2pocws1.sql.azuresynapse.net"
					},
					"SQLDedicatedPoolName": {
						"type": "string",
						"defaultValue": "ajmnugiqxczz6x2pocws1p1"
					},
					"SQLLoginUsername": {
						"type": "string",
						"defaultValue": "testlogin"
					},
					"KeyVaultName": {
						"type": "string",
						"defaultValue": "kvajmnugiqxczz6x2poc"
					},
					"datalakeAccountName": {
						"type": "string",
						"defaultValue": "ajmnugiqxczz6x2poc"
					}
				},
				"folder": {
					"name": "TripFaresDataPipeline"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/tripsDataSource')]",
				"[concat(variables('workspaceId'), '/datasets/tripDataSink')]",
				"[concat(variables('workspaceId'), '/datasets/faresDataSource')]",
				"[concat(variables('workspaceId'), '/datasets/faresDataSink')]",
				"[concat(variables('workspaceId'), '/dataflows/tripFaresDataTransformations')]",
				"[concat(variables('workspaceId'), '/datasets/azureSynapseAnalyticsSchema')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/copy_fare_pipeline')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "copy-fares-datacsv",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlServerSource",
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"sink": {
								"type": "DelimitedTextSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								},
								"formatSettings": {
									"type": "DelimitedTextWriteSettings",
									"quoteAllText": true,
									"fileExtension": ".csv"
								}
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"mappings": [
									{
										"source": {
											"name": "medallion",
											"type": "String",
											"physicalType": "nvarchar"
										},
										"sink": {
											"name": "medallion",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "hack_license",
											"type": "String",
											"physicalType": "nvarchar"
										},
										"sink": {
											"name": "hack_license",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "vendor_id",
											"type": "String",
											"physicalType": "nvarchar"
										},
										"sink": {
											"name": "vendor_id",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "pickup_datetime",
											"type": "DateTime",
											"physicalType": "datetime2"
										},
										"sink": {
											"name": "pickup_datetime",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "payment_type",
											"type": "String",
											"physicalType": "nvarchar"
										},
										"sink": {
											"name": "payment_type",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "fare_amount",
											"type": "Double",
											"physicalType": "float"
										},
										"sink": {
											"name": "fare_amount",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "surcharge",
											"type": "String",
											"physicalType": "nvarchar"
										},
										"sink": {
											"name": "surcharge",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "mta_tax",
											"type": "Double",
											"physicalType": "float"
										},
										"sink": {
											"name": "mta_tax",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "tip_amount",
											"type": "String",
											"physicalType": "nvarchar"
										},
										"sink": {
											"name": "tip_amount",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "tolls_amount",
											"type": "String",
											"physicalType": "nvarchar"
										},
										"sink": {
											"name": "tolls_amount",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "total_amount",
											"type": "Double",
											"physicalType": "float"
										},
										"sink": {
											"name": "total_amount",
											"type": "String",
											"physicalType": "String"
										}
									}
								],
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "dataset_sqlserver_table",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "Dataset_adls_gen2_rawdata",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/dataset_sqlserver_table')]",
				"[concat(variables('workspaceId'), '/datasets/Dataset_adls_gen2_rawdata')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Dataset')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_gen2AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "refined",
						"fileSystem": "rawdata"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"quoteChar": "\""
				},
				"schema": [
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ls_gen2AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Dataset_adls_gen2_rawdata')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_adls_gen2_rawdata",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileSystem": "rawdata"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ls_adls_gen2_rawdata')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DestinationDataset_zcj')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_gen2AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileSystem": "rawdata"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ls_gen2AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SourceDataset_zcj')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "LSV2_SqlServer1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "SqlServerTable",
				"schema": [
					{
						"name": "medallion",
						"type": "nvarchar"
					},
					{
						"name": "hack_license",
						"type": "nvarchar"
					},
					{
						"name": "vendor_id",
						"type": "nvarchar"
					},
					{
						"name": "rate_code",
						"type": "nvarchar"
					},
					{
						"name": "store_and_fwd_flag",
						"type": "nvarchar"
					},
					{
						"name": "pickup_datetime",
						"type": "datetime2",
						"scale": 7
					},
					{
						"name": "dropoff_datetime",
						"type": "datetime2",
						"scale": 7
					},
					{
						"name": "passenger_count",
						"type": "nvarchar"
					},
					{
						"name": "trip_time_in_secs",
						"type": "nvarchar"
					},
					{
						"name": "trip_distance",
						"type": "float",
						"precision": 15
					},
					{
						"name": "pickup_longitude",
						"type": "nvarchar"
					},
					{
						"name": "pickup_latitude",
						"type": "nvarchar"
					},
					{
						"name": "dropoff_longitude",
						"type": "nvarchar"
					},
					{
						"name": "dropoff_latitude",
						"type": "nvarchar"
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "trip-data"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/LSV2_SqlServer1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/azureSynapseAnalyticsSchema')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "TripFaresSynapseAnalyticsLinkedService",
					"type": "LinkedServiceReference",
					"parameters": {
						"SynapseWorkspaceName": {
							"value": "@dataset().SynapseWorkspaceName",
							"type": "Expression"
						},
						"SQLDedicatedPoolName": {
							"value": "@dataset().SQLDedicatedPoolName",
							"type": "Expression"
						},
						"keyVaultName": {
							"value": "@dataset().keyVaultName",
							"type": "Expression"
						},
						"SQLLoginUsername": {
							"value": "@dataset().SQLLoginUsername",
							"type": "Expression"
						}
					}
				},
				"parameters": {
					"SynapseWorkspaceName": {
						"type": "string"
					},
					"SQLDedicatedPoolName": {
						"type": "string"
					},
					"keyVaultName": {
						"type": "string"
					},
					"SQLLoginUsername": {
						"type": "string"
					}
				},
				"folder": {
					"name": "TripFareDatasets"
				},
				"annotations": [],
				"type": "AzureSqlDWTable",
				"schema": [],
				"typeProperties": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/TripFaresSynapseAnalyticsLinkedService')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/azureSynapseAnalyticsTable')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "TripFaresSynapseAnalyticsLinkedService",
					"type": "LinkedServiceReference",
					"parameters": {
						"SynapseWorkspaceName": {
							"value": "@dataset().SynapseWorkspaceName",
							"type": "Expression"
						},
						"SQLDedicatedPoolName": {
							"value": "@dataset().SQLDedicatedPoolName",
							"type": "Expression"
						},
						"keyVaultName": {
							"value": "@dataset().keyVaultName",
							"type": "Expression"
						},
						"SQLLoginUsername": {
							"value": "@dataset().SQLLoginUsername",
							"type": "Expression"
						}
					}
				},
				"parameters": {
					"SchemaName": {
						"type": "string"
					},
					"SynapseWorkspaceName": {
						"type": "string"
					},
					"SQLDedicatedPoolName": {
						"type": "string"
					},
					"keyVaultName": {
						"type": "string"
					},
					"SQLLoginUsername": {
						"type": "string"
					}
				},
				"folder": {
					"name": "TripFareDatasets"
				},
				"annotations": [],
				"type": "AzureSqlDWTable",
				"schema": [],
				"typeProperties": {
					"schema": {
						"value": "@dataset().SchemaName",
						"type": "Expression"
					},
					"table": "AggregateTaxiData"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/TripFaresSynapseAnalyticsLinkedService')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dataset_sqlserver_table')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "LSV2_SqlServer1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "SqlServerTable",
				"schema": [
					{
						"name": "medallion",
						"type": "nvarchar"
					},
					{
						"name": "hack_license",
						"type": "nvarchar"
					},
					{
						"name": "vendor_id",
						"type": "nvarchar"
					},
					{
						"name": "pickup_datetime",
						"type": "datetime2",
						"scale": 7
					},
					{
						"name": "payment_type",
						"type": "nvarchar"
					},
					{
						"name": "fare_amount",
						"type": "float",
						"precision": 15
					},
					{
						"name": "surcharge",
						"type": "nvarchar"
					},
					{
						"name": "mta_tax",
						"type": "float",
						"precision": 15
					},
					{
						"name": "tip_amount",
						"type": "nvarchar"
					},
					{
						"name": "tolls_amount",
						"type": "nvarchar"
					},
					{
						"name": "total_amount",
						"type": "float",
						"precision": 15
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "fares-data"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/LSV2_SqlServer1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/faresDataSink')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "TripFaresDataLakeStorageLinkedService",
					"type": "LinkedServiceReference",
					"parameters": {
						"keyVaultName": {
							"value": "@dataset().keyVaultName",
							"type": "Expression"
						},
						"datalakeAccountName": {
							"value": "@dataset().datalakeAccountName",
							"type": "Expression"
						}
					}
				},
				"parameters": {
					"keyVaultName": {
						"type": "string",
						"defaultValue": "kvmsft"
					},
					"datalakeAccountName": {
						"type": "string",
						"defaultValue": "adlsmsft"
					}
				},
				"folder": {
					"name": "TripFareDatasets"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "fares-data.csv",
						"fileSystem": "public"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "medallion",
						"type": "String"
					},
					{
						"name": "hack_license",
						"type": "String"
					},
					{
						"name": "vendor_id",
						"type": "String"
					},
					{
						"name": "pickup_datetime",
						"type": "String"
					},
					{
						"name": "payment_type",
						"type": "String"
					},
					{
						"name": "fare_amount",
						"type": "String"
					},
					{
						"name": "surcharge",
						"type": "String"
					},
					{
						"name": "mta_tax",
						"type": "String"
					},
					{
						"name": "tip_amount",
						"type": "String"
					},
					{
						"name": "tolls_amount",
						"type": "String"
					},
					{
						"name": "total_amount",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/TripFaresDataLakeStorageLinkedService')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/faresDataSource')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "HttpServerTripFareDataLinkedService",
					"type": "LinkedServiceReference"
				},
				"folder": {
					"name": "TripFareDatasets"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "HttpServerLocation"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/HttpServerTripFareDataLinkedService')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/tripDataSink')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "TripFaresDataLakeStorageLinkedService",
					"type": "LinkedServiceReference",
					"parameters": {
						"keyVaultName": {
							"value": "@dataset().keyVaultName",
							"type": "Expression"
						},
						"datalakeAccountName": {
							"value": "@dataset().datalakeAccountName",
							"type": "Expression"
						}
					}
				},
				"parameters": {
					"datalakeAccountName": {
						"type": "string"
					},
					"keyVaultName": {
						"type": "string"
					}
				},
				"folder": {
					"name": "TripFareDatasets"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "trip-data.csv",
						"fileSystem": "public"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "medallion",
						"type": "String"
					},
					{
						"name": "hack_license",
						"type": "String"
					},
					{
						"name": "vendor_id",
						"type": "String"
					},
					{
						"name": "rate_code",
						"type": "String"
					},
					{
						"name": "store_and_fwd_flag",
						"type": "String"
					},
					{
						"name": "pickup_datetime",
						"type": "String"
					},
					{
						"name": "dropoff_datetime",
						"type": "String"
					},
					{
						"name": "passenger_count",
						"type": "String"
					},
					{
						"name": "trip_time_in_secs",
						"type": "String"
					},
					{
						"name": "trip_distance",
						"type": "String"
					},
					{
						"name": "pickup_longitude",
						"type": "String"
					},
					{
						"name": "pickup_latitude",
						"type": "String"
					},
					{
						"name": "dropoff_longitude",
						"type": "String"
					},
					{
						"name": "dropoff_latitude",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/TripFaresDataLakeStorageLinkedService')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/tripsDataSource')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "HttpServerTripDataLinkedService",
					"type": "LinkedServiceReference"
				},
				"folder": {
					"name": "TripFareDatasets"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "HttpServerLocation"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/HttpServerTripDataLinkedService')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/HttpServerTripDataLinkedService')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "HttpServer",
				"typeProperties": {
					"url": "[parameters('HttpServerTripDataLinkedService_properties_typeProperties_url')]",
					"enableServerCertificateValidation": true,
					"authenticationType": "Anonymous"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/HttpServerTripFareDataLinkedService')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "HttpServer",
				"typeProperties": {
					"url": "[parameters('HttpServerTripFareDataLinkedService_properties_typeProperties_url')]",
					"enableServerCertificateValidation": true,
					"authenticationType": "Anonymous"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/LSV2_SqlServer1')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "SqlServer",
				"typeProperties": {
					"connectionString": "[parameters('LSV2_SqlServer1_connectionString')]"
				},
				"connectVia": {
					"referenceName": "SHIntegrationRuntime1",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/SHIntegrationRuntime1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TripFaresDataLakeStorageLinkedService')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"keyVaultName": {
						"type": "string"
					},
					"datalakeAccountName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('TripFaresDataLakeStorageLinkedService_properties_typeProperties_url')]",
					"accountKey": {
						"type": "AzureKeyVaultSecret",
						"store": {
							"referenceName": "keyVaultLinkedservice",
							"type": "LinkedServiceReference",
							"parameters": {
								"keyVaultName": {
									"value": "@linkedService().keyVaultName",
									"type": "Expression"
								}
							}
						},
						"secretName": "adlsAccessKey"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]",
				"[concat(variables('workspaceId'), '/linkedServices/keyVaultLinkedservice')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TripFaresSynapseAnalyticsLinkedService')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"SynapseWorkspaceName": {
						"type": "string"
					},
					"SQLDedicatedPoolName": {
						"type": "string"
					},
					"keyVaultName": {
						"type": "string"
					},
					"SQLLoginUsername": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('TripFaresSynapseAnalyticsLinkedService_connectionString')]",
					"password": {
						"type": "AzureKeyVaultSecret",
						"store": {
							"referenceName": "keyVaultLinkedservice",
							"type": "LinkedServiceReference",
							"parameters": {
								"keyVaultName": {
									"value": "@linkedService().keyVaultName",
									"type": "Expression"
								}
							}
						},
						"secretName": "synapseSqlLoginPassword"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]",
				"[concat(variables('workspaceId'), '/linkedServices/keyVaultLinkedservice')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/keyVaultLinkedservice')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"keyVaultName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "AzureKeyVault",
				"typeProperties": {
					"baseUrl": "[parameters('keyVaultLinkedservice_properties_typeProperties_baseUrl')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ls_adls_gen2_rawdata')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('ls_adls_gen2_rawdata_properties_typeProperties_url')]",
					"accountKey": {
						"type": "SecureString",
						"value": "[parameters('ls_adls_gen2_rawdata_accountKey')]"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ls_gen2AzureDataLakeStorage1')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('ls_gen2AzureDataLakeStorage1_properties_typeProperties_url')]",
					"accountKey": {
						"type": "SecureString",
						"value": "[parameters('ls_gen2AzureDataLakeStorage1_accountKey')]"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/nyc_tlc_yellow')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobStorage",
				"typeProperties": {
					"sasUri": "[parameters('nyc_tlc_yellow_sasUri')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ScheduleTrigger 1')]",
			"type": "Microsoft.Synapse/workspaces/triggers",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"runtimeState": "Stopped",
				"pipelines": [],
				"type": "ScheduleTrigger",
				"typeProperties": {
					"recurrence": {
						"frequency": "Minute",
						"interval": 15,
						"startTime": "2021-08-02T23:33:00Z",
						"timeZone": "UTC"
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoIntegrationRuntime1')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0,
							"cleanup": false
						}
					}
				},
				"managedVirtualNetwork": {
					"type": "ManagedVirtualNetworkReference",
					"referenceName": "default"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/managedVirtualNetworks/default')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				},
				"managedVirtualNetwork": {
					"type": "ManagedVirtualNetworkReference",
					"referenceName": "default"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/managedVirtualNetworks/default')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SHIntegrationRuntime1')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "SelfHosted",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/tripFaresDataTransformations')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "TripFaresDataFlow"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "tripDataSink",
								"type": "DatasetReference"
							},
							"name": "TripDataCSV"
						},
						{
							"dataset": {
								"referenceName": "faresDataSink",
								"type": "DatasetReference"
							},
							"name": "FaresDataCSV"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "azureSynapseAnalyticsTable",
								"type": "DatasetReference"
							},
							"name": "SynapseAnalyticsSink"
						}
					],
					"transformations": [
						{
							"name": "AggregateByPaymentType"
						},
						{
							"name": "InnerJoinWithTripFares"
						}
					],
					"script": "source(output(\n\t\tmedallion as string,\n\t\thack_license as string,\n\t\tvendor_id as string,\n\t\trate_code as string,\n\t\tstore_and_fwd_flag as string,\n\t\tpickup_datetime as string,\n\t\tdropoff_datetime as string,\n\t\tpassenger_count as string,\n\t\ttrip_time_in_secs as string,\n\t\ttrip_distance as string,\n\t\tpickup_longitude as string,\n\t\tpickup_latitude as string,\n\t\tdropoff_longitude as string,\n\t\tdropoff_latitude as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tinferDriftedColumnTypes: true,\n\tignoreNoFilesFound: false) ~> TripDataCSV\nsource(output(\n\t\tmedallion as string,\n\t\thack_license as string,\n\t\tvendor_id as string,\n\t\tpickup_datetime as string,\n\t\tpayment_type as string,\n\t\tfare_amount as string,\n\t\tsurcharge as string,\n\t\tmta_tax as string,\n\t\ttip_amount as string,\n\t\ttolls_amount as string,\n\t\ttotal_amount as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tinferDriftedColumnTypes: true,\n\tignoreNoFilesFound: false) ~> FaresDataCSV\nInnerJoinWithTripFares aggregate(groupBy(payment_type),\n\taverage_fare = avg(toInteger(total_amount)),\n\t\ttotal_trip_distance = sum(toInteger(trip_distance))) ~> AggregateByPaymentType\nTripDataCSV, FaresDataCSV join(TripDataCSV@medallion == FaresDataCSV@medallion\n\t&& TripDataCSV@hack_license == FaresDataCSV@hack_license\n\t&& TripDataCSV@vendor_id == FaresDataCSV@vendor_id\n\t&& TripDataCSV@pickup_datetime == FaresDataCSV@pickup_datetime,\n\tjoinType:'inner',\n\tbroadcast: 'auto')~> InnerJoinWithTripFares\nAggregateByPaymentType sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tdeletable:false,\n\tinsertable:true,\n\tupdateable:false,\n\tupsertable:false,\n\trecreate:true,\n\tformat: 'table',\n\tstaged: false,\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\terrorHandlingOption: 'stopOnFirstError') ~> SynapseAnalyticsSink"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/tripDataSink')]",
				"[concat(variables('workspaceId'), '/datasets/faresDataSink')]",
				"[concat(variables('workspaceId'), '/datasets/azureSynapseAnalyticsTable')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Analyze Azure Open Datasets using serverless SQL pool')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "/*\nFull tutorial available on: https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/tutorial-data-analyst\nIn this tutorial, you learn how to perform exploratory data analysis by combining different Azure Open Datasets using serverless SQL pool and then visualizing the results in Azure Synapse Studio.\n\nIn particular, you analyze the New York City (NYC) Taxi dataset that includes:\n\n - Pickup and drop-off dates and times.\n - Pick up and drop-off locations.\n - Trip distances.\n - Itemized fares.\n - Rate types.\n - Payment types.\n - Driver-reported passenger counts.*/\n\n\n/*\n * * * * * * * * * * * * * * * *\n * Automatic schema inference  *\n * * * * * * * * * * * * * * * *\n\nSince data is stored in the Parquet file format, automatic schema inference is available. You can easily query the data without listing the data types of all columns in the files. You also can use the virtual column mechanism and the filepath function to filter out a certain subset of files.\n\nLet's first get familiar with the NYC Taxi data by running the following query. */\n\nSELECT TOP 100 * FROM\n    OPENROWSET(\n        BULK 'https://azureopendatastorage.blob.core.windows.net/nyctlc/yellow/puYear=*/puMonth=*/*.parquet',\n        FORMAT='PARQUET'\n    ) AS [nyc];\n\n\n/* Similarly, you can query the Public Holidays dataset by using the following query. */\n\nSELECT TOP 100 * FROM\n    OPENROWSET(\n        BULK 'https://azureopendatastorage.blob.core.windows.net/holidaydatacontainer/Processed/*.parquet',\n        FORMAT='PARQUET'\n    ) AS [holidays];\n\n/* Lastly, you can also query the Weather Data dataset by using the following query. */\n\nSELECT\n    TOP 100 *\nFROM\n    OPENROWSET(\n        BULK 'https://azureopendatastorage.blob.core.windows.net/isdweatherdatacontainer/ISDWeather/year=*/month=*/*.parquet',\n        FORMAT='PARQUET'\n    ) AS [weather];\n\n/* You can learn more about the meaning of the individual columns in the descriptions\nof the NYC Taxi, Public Holidays, and Weather Data datasets on the Azure Opendatasets page. */\n\n\n/*\n * * * * * * * * * * * * * * * * * * * * * * * * * *\n * Time series, seasonality, and outlier analysis  *\n * * * * * * * * * * * * * * * * * * * * * * * * * *\nYou can easily summarize the yearly number of taxi rides by using the following query. */\n\nSELECT\n    YEAR(tpepPickupDateTime) AS current_year,\n    COUNT(*) AS rides_per_year\nFROM\n    OPENROWSET(\n        BULK 'https://azureopendatastorage.blob.core.windows.net/nyctlc/yellow/puYear=*/puMonth=*/*.parquet',\n        FORMAT='PARQUET'\n    ) AS [nyc]\nWHERE nyc.filepath(1) >= '2009' AND nyc.filepath(1) <= '2019'\nGROUP BY YEAR(tpepPickupDateTime)\nORDER BY 1 ASC;\n\n/* The data can be visualized in Synapse Studio by switching from the Table to the Chart view.\nYou can choose among different chart types, such as Area, Bar, Column, Line, Pie, and Scatter.\nIn this case, plot the Column chart with the Category column set to current_year.\n\nFrom this visualization, a trend of a decreasing number of rides over years can be clearly seen.\nPresumably, this decrease is due to the recent increased popularity of ride-sharing companies.\n*/\n\n/* Next, let's focus the analysis on a single year, for example, 2016.\nThe following query returns the daily number of rides during that year. */\n\nSELECT\n    CAST([tpepPickupDateTime] AS DATE) AS [current_day],\n    COUNT(*) as rides_per_day\nFROM\n    OPENROWSET(\n        BULK 'https://azureopendatastorage.blob.core.windows.net/nyctlc/yellow/puYear=*/puMonth=*/*.parquet',\n        FORMAT='PARQUET'\n    ) AS [nyc]\nWHERE nyc.filepath(1) = '2016'\nGROUP BY CAST([tpepPickupDateTime] AS DATE)\nORDER BY 1 ASC;\n\n/* Again, you can easily visualize data by plotting the Column chart with\nthe Category column set to current_day and the Legend (series) column set to rides_per_day. */\n\n/* From the plot chart, you can see that there's a weekly pattern, with Saturdays as the peak day.\nDuring summer months, there are fewer taxi rides because of vacations.\nThere are also some significant drops in the number of taxi rides without a clear pattern of when and why they occur. */\n\n/* Next, let's see if the drops correlate with public holidays by joining the NYC Taxi rides dataset with the Public Holidays dataset. */\n\nWITH taxi_rides AS\n(\n    SELECT\n        CAST([tpepPickupDateTime] AS DATE) AS [current_day],\n        COUNT(*) as rides_per_day\n    FROM\n        OPENROWSET(\n            BULK 'https://azureopendatastorage.blob.core.windows.net/nyctlc/yellow/puYear=*/puMonth=*/*.parquet',\n            FORMAT='PARQUET'\n        ) AS [nyc]\n    WHERE nyc.filepath(1) = '2016'\n    GROUP BY CAST([tpepPickupDateTime] AS DATE)\n),\npublic_holidays AS\n(\n    SELECT\n        holidayname as holiday,\n        date\n    FROM\n        OPENROWSET(\n            BULK 'https://azureopendatastorage.blob.core.windows.net/holidaydatacontainer/Processed/*.parquet',\n            FORMAT='PARQUET'\n        ) AS [holidays]\n    WHERE countryorregion = 'United States' AND YEAR(date) = 2016\n)\nSELECT\n*\nFROM taxi_rides t\nLEFT OUTER JOIN public_holidays p on t.current_day = p.date\nORDER BY current_day ASC;\n\n/* This time, we want to highlight the number of taxi rides during public holidays.\nFor that purpose, we choose none for the Category column and rides_per_day and holiday as the Legend (series) columns. */\n\n/* From the plot chart, you can see that during public holidays the number of taxi rides is lower.\nThere's still one unexplained large drop on January 23. Let's check the weather in NYC on that day by querying the Weather Data dataset. */\n\nSELECT\n    AVG(windspeed) AS avg_windspeed,\n    MIN(windspeed) AS min_windspeed,\n    MAX(windspeed) AS max_windspeed,\n    AVG(temperature) AS avg_temperature,\n    MIN(temperature) AS min_temperature,\n    MAX(temperature) AS max_temperature,\n    AVG(sealvlpressure) AS avg_sealvlpressure,\n    MIN(sealvlpressure) AS min_sealvlpressure,\n    MAX(sealvlpressure) AS max_sealvlpressure,\n    AVG(precipdepth) AS avg_precipdepth,\n    MIN(precipdepth) AS min_precipdepth,\n    MAX(precipdepth) AS max_precipdepth,\n    AVG(snowdepth) AS avg_snowdepth,\n    MIN(snowdepth) AS min_snowdepth,\n    MAX(snowdepth) AS max_snowdepth\nFROM\n    OPENROWSET(\n        BULK 'https://azureopendatastorage.blob.core.windows.net/isdweatherdatacontainer/ISDWeather/year=*/month=*/*.parquet',\n        FORMAT='PARQUET'\n    ) AS [weather]\nWHERE countryorregion = 'US' AND CAST([datetime] AS DATE) = '2016-01-23' AND stationname = 'JOHN F KENNEDY INTERNATIONAL AIRPORT';\n\n/* The results of the query indicate that the drop in the number of taxi rides occurred because:\n\n1. There was a blizzard on that day in NYC with heavy snow (~30 cm).\n2. It was cold (temperature was below zero degrees Celsius).\n3. It was windy (~10 m/s). */\n\n\n/* This tutorial has shown how a data analyst can quickly perform exploratory data analysis, easily combine different\ndatasets by using serverless SQL pool, and visualize the results by using Azure Synapse Studio. */\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"poolName": "Built-in",
						"databaseName": "AC_Transport_serverlessDB"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Create external table in serverlessDB')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "IF NOT EXISTS (SELECT * FROM sys.external_file_formats WHERE name = 'SynapseParquetFormat') \n\tCREATE EXTERNAL FILE FORMAT [SynapseParquetFormat] \n\tWITH ( FORMAT_TYPE = PARQUET)\nGO\n\nIF NOT EXISTS (SELECT * FROM sys.external_data_sources WHERE name = 'nyctlc_azureopendatastorage_blob_core_windows_net') \n\tCREATE EXTERNAL DATA SOURCE [nyctlc_azureopendatastorage_blob_core_windows_net] \n\tWITH (\n\t\tLOCATION   = 'https://azureopendatastorage.blob.core.windows.net/nyctlc', \n\t)\nGo\n\nCREATE EXTERNAL TABLE nyc_yellow_taxi (\n\t[vendorID] varchar(8000),\n\t[tpepPickupDateTime] datetime2(7),\n\t[tpepDropoffDateTime] datetime2(7),\n\t[passengerCount] int,\n\t[tripDistance] float,\n\t[puLocationId] varchar(8000),\n\t[doLocationId] varchar(8000),\n\t[startLon] float,\n\t[startLat] float,\n\t[endLon] float,\n\t[endLat] float,\n\t[rateCodeId] int,\n\t[storeAndFwdFlag] varchar(8000),\n\t[paymentType] varchar(8000),\n\t[fareAmount] float,\n\t[extra] float,\n\t[mtaTax] float,\n\t[improvementSurcharge] varchar(8000),\n\t[tipAmount] float,\n\t[tollsAmount] float,\n\t[totalAmount] float\n\t)\n\tWITH (\n\tLOCATION = 'yellow/puYear=*/puMonth=*/*.parquet',\n\tDATA_SOURCE = [nyctlc_azureopendatastorage_blob_core_windows_net],\n\tFILE_FORMAT = [SynapseParquetFormat]\n\t)\nGO\n\nSELECT TOP 100 * FROM nyc_yellow_taxi\nGO\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"poolName": "Built-in",
						"databaseName": "AC_Transport_serverlessDB"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Create_external_table_in_ac_transit_serverless')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE SCHEMA trips\n\n-- DROP EXTERNAL FILE FORMAT [trip_csv_file_format]\n-- GO\nCREATE EXTERNAL FILE FORMAT [trip_csv_file_format]\nWITH (FORMAT_TYPE = DELIMITEDTEXT)\n\n--DROP EXTERNAL DATA SOURCE trip_data_source_adls_refined\n--GO\nCREATE EXTERNAL DATA SOURCE trip_data_source_adls_refined\nWITH (LOCATION = 'https://ajmnugiqxczz6x2poc.blob.core.windows.net/rawdata')\n\nDROP EXTERNAL TABLE trips.[trip_data]\n\nCREATE EXTERNAL TABLE trips.[trip_data]\n(\n\t[medallion] [nvarchar](50) ,\n\t[hack_license] [nvarchar](50),\n\t[vendor_id] [nvarchar](50),\n\t[rate_code] [nvarchar](50),\n\t[store_and_fwd_flag] [nvarchar](50),\n\t[pickup_datetime] [datetime2](7),\n\t[dropoff_datetime] [datetime2](7),\n\t[passenger_count] [nvarchar](50),\n\t[trip_time_in_secs] [nvarchar](50),\n\t[trip_distance] [float],\n\t[pickup_longitude] [nvarchar](50),\n\t[pickup_latitude] [nvarchar](50),\n\t[dropoff_longitude] [nvarchar](50),\n\t[dropoff_latitude] [nvarchar](50)\n)\nWITH\n(\n\tLOCATION = 'rawdata/dbo.trip-data.csv',\n\tDATA_SOURCE = [trip_data_source_adls_refined],\n\tFILE_FORMAT = [trip_csv_file_format]\n)\n\nSELECT TOP 10 * FROM trips.[trip_data]",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"poolName": "Built-in",
						"databaseName": "AC_Transport_serverlessDB"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Querying_fare_data_adls_refined')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT\nTOP100*\nFROM\nOPENROWSET(\nBULK'https://ajmnugiqxczz6x2poc.dfs.core.windows.net/rawdata/refined/dbo.fares-data.csv',\nFORMAT='CSV',\nPARSER_VERSION='2.0',\n        HEADER_ROW = TRUE\n    )AS[result]\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"poolName": "Built-in",
						"databaseName": "master"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Querying_trip_data__ADLS_refined')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT\nTOP100*\nFROM\nOPENROWSET(\nBULK'https://ajmnugiqxczz6x2poc.dfs.core.windows.net/rawdata/refined/dbo.trip-data.csv',\nFORMAT='CSV',\nPARSER_VERSION='2.0'    \n    ) \nWITH\n    (\n    [medallion] [nvarchar](50),\n\t[hack_license] [nvarchar](50),\n\t[vendor_id] [nvarchar](50),\n\t[rate_code] [nvarchar](50),\n\t[store_and_fwd_flag] [nvarchar](50),\n\t[pickup_datetime] [datetime2](7),\n\t[dropoff_datetime] [datetime2](7),\n\t[passenger_count] [nvarchar](50),\n\t[trip_time_in_secs] [nvarchar](50),\n\t[trip_distance] [float],\n\t[pickup_longitude] [nvarchar](50),\n\t[pickup_latitude] [nvarchar](50),\n\t[dropoff_longitude] [nvarchar](50),\n\t[dropoff_latitude] [nvarchar](50) \n\n    ) AS [result];\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"poolName": "Built-in",
						"databaseName": "master"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Querying_trip_data_from_ADLS_rawdata')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "\nSELECT\n    TOP100*\nFROM\n    OPENROWSET(\n        BULK'https://ajmnugiqxczz6x2poc.blob.core.windows.net/rawdata/dbo.trip-data.txt',\n        FORMAT='CSV',\n        HEADER_ROW = TRUE\n    ) \nWITH\n    (\n    [medallion] [nvarchar](50),\n\t[hack_license] [nvarchar](50),\n\t[vendor_id] [nvarchar](50),\n\t[rate_code] [nvarchar](50),\n\t[store_and_fwd_flag] [nvarchar](50),\n\t[pickup_datetime] [datetime2](7),\n\t[dropoff_datetime] [datetime2](7),\n\t[passenger_count] [nvarchar](50),\n\t[trip_time_in_secs] [nvarchar](50),\n\t[trip_distance] [float],\n\t[pickup_longitude] [nvarchar](50),\n\t[pickup_latitude] [nvarchar](50),\n\t[dropoff_longitude] [nvarchar](50),\n\t[dropoff_latitude] [nvarchar](50) \n\n    ) AS [result];\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"poolName": "Built-in",
						"databaseName": "default"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 1')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT TOP (100) [vendorID]\n,[tpepPickupDateTime]\n,[tpepDropoffDateTime]\n,[passengerCount]\n,[tripDistance]\n,[puLocationId]\n,[doLocationId]\n,[startLon]\n,[startLat]\n,[endLon]\n,[endLat]\n,[rateCodeId]\n,[storeAndFwdFlag]\n,[paymentType]\n,[fareAmount]\n,[extra]\n,[mtaTax]\n,[improvementSurcharge]\n,[tipAmount]\n,[tollsAmount]\n,[totalAmount]\n FROM [dbo].[nyc_yellow_taxi]",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"poolName": "Built-in",
						"databaseName": "serverlessv2"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/count_yellow_taxi_rows')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "-- This is auto-generated code\nSELECT\n    count(*) row_count\nFROM\n    OPENROWSET(\n        BULK'https://azureopendatastorage.blob.core.windows.net/nyctlc/yellow/puYear=*/puMonth=*/*.parquet',\n        FORMAT='parquet'\n    ) AS [result];",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"poolName": "Built-in",
						"databaseName": "master"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/external_tbl_taxi')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "IF NOT EXISTS (SELECT * FROM sys.external_file_formats WHERE name = 'SynapseParquetFormat') \n\tCREATE EXTERNAL FILE FORMAT [SynapseParquetFormat] \n\tWITH ( FORMAT_TYPE = PARQUET)\nGO\n\nIF NOT EXISTS (SELECT * FROM sys.external_data_sources WHERE name = 'nyctlc_azureopendatastorage_blob_core_windows_net') \n\tCREATE EXTERNAL DATA SOURCE [nyctlc_azureopendatastorage_blob_core_windows_net] \n\tWITH (\n\t\tLOCATION   = 'https://azureopendatastorage.blob.core.windows.net/nyctlc', \n\t)\nGo\n\nCREATE EXTERNAL TABLE taxi_data_v1 (\n\t[vendorID] varchar(8000),\n\t[tpepPickupDateTime] datetime2(7),\n\t[tpepDropoffDateTime] datetime2(7),\n\t[passengerCount] int,\n\t[tripDistance] float,\n\t[puLocationId] varchar(8000),\n\t[doLocationId] varchar(8000),\n\t[startLon] float,\n\t[startLat] float,\n\t[endLon] float,\n\t[endLat] float,\n\t[rateCodeId] int,\n\t[storeAndFwdFlag] varchar(8000),\n\t[paymentType] varchar(8000),\n\t[fareAmount] float,\n\t[extra] float,\n\t[mtaTax] float,\n\t[improvementSurcharge] varchar(8000),\n\t[tipAmount] float,\n\t[tollsAmount] float,\n\t[totalAmount] float\n\t)\n\tWITH (\n\tLOCATION = 'yellow/puYear=*/puMonth=*/*.parquet',\n\tDATA_SOURCE = [nyctlc_azureopendatastorage_blob_core_windows_net],\n\tFILE_FORMAT = [SynapseParquetFormat]\n\t)\nGO\n\nSELECT TOP 100 * FROM taxi_data_v1\nGO\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"poolName": "Built-in",
						"databaseName": "AC_Transport_serverlessDB"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/select top 100 from tripdatacsv')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT\nTOP100*\nFROM\nOPENROWSET(\nBULK'https://ajmnugiqxczz6x2poc.dfs.core.windows.net/rawdata/dbo.trip-data.csv',\nFORMAT='CSV',\nPARSER_VERSION='2.0',\n        HEADER_ROW = TRUE\n    )AS[result]\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"poolName": "Built-in",
						"databaseName": "AC_Transport_serverlessDB"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/vw_fares_data_AC_Transit')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "USE AC_Transport_serverlessDB;\nGO\n\nDROP VIEW IF EXISTS vwfares_data;\nGO\n\nCREATE VIEW vwfares_data AS\nSELECT\n*\nFROM\nOPENROWSET(\nBULK'https://ajmnugiqxczz6x2poc.dfs.core.windows.net/rawdata/dbo.fares-data.csv',\nFORMAT='CSV',\nPARSER_VERSION='2.0'\n    )AS[result]\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"poolName": "Built-in",
						"databaseName": "AC_Transport_serverlessDB"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/vw_trip_data_AC_Transit_serverlessDB')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "USE AC_Transport_serverlessDB;\nGO\n\nDROP VIEW IF EXISTS dbo.vwtrip_data;\nGO\n\nCREATE VIEW vwtrip_data AS\nSELECT\n*\nFROM\nOPENROWSET(\nBULK'https://ajmnugiqxczz6x2poc.dfs.core.windows.net/rawdata/dbo.trip-data.csv',\nFORMAT='CSV',\nPARSER_VERSION='2.0',\n        HEADER_ROW = TRUE\n    )AS[result]\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"poolName": "Built-in",
						"databaseName": "AC_Transport_serverlessDB"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Data Exploration and ML Modeling - NYC taxi predict using Spark MLlib')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ws1sparkpool1",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/edf6dd9d-7c4a-4bca-a997-945f3d60cf4e/resourceGroups/rg-poc-test/providers/Microsoft.Synapse/workspaces/ajmnugiqxczz6x2pocws1/bigDataPools/ws1sparkpool1",
						"name": "ws1sparkpool1",
						"type": "Spark",
						"endpoint": "https://ajmnugiqxczz6x2pocws1.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ws1sparkpool1",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 5,
						"cores": 8,
						"memory": 56
					}
				},
				"cells": [
					{
						"cell_type": "markdown",
						"source": [
							"# Predict NYC Taxi Tips using Spark ML and Azure Open Datasets\n",
							"\n",
							"The notebook ingests, visualizes, prepares and then trains a model based on an Open Dataset that tracks NYC Yellow Taxi trips and various attributes around them.\n",
							"The goal is to predict for a given trip whether there will be a tip or not.\n",
							"\n",
							" https://docs.microsoft.com/en-us/azure/synapse-analytics/spark/apache-spark-machine-learning-mllib-notebook\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"import matplotlib.pyplot as plt\n",
							"\n",
							"from pyspark.sql.functions import unix_timestamp\n",
							"\n",
							"from pyspark.sql import SparkSession\n",
							"from pyspark.sql.types import *\n",
							"from pyspark.sql.functions import *\n",
							"\n",
							"from pyspark.ml import Pipeline\n",
							"from pyspark.ml import PipelineModel\n",
							"from pyspark.ml.feature import RFormula\n",
							"from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer\n",
							"from pyspark.ml.classification import LogisticRegression\n",
							"from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
							"from pyspark.ml.evaluation import BinaryClassificationEvaluator"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Ingest Data \n",
							"\n",
							"Get a sample data of nyc yellow taxi to make it faster/easier to evaluate different approaches to prep for the modelling phase later in the notebook."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# Import NYC yellow cab data from Azure Open Datasets\n",
							"from azureml.opendatasets import NycTlcYellow\n",
							"\n",
							"from datetime import datetime\n",
							"from dateutil import parser\n",
							"\n",
							"end_date = parser.parse('2018-05-08 00:00:00')\n",
							"start_date = parser.parse('2018-05-01 00:00:00')\n",
							"\n",
							"nyc_tlc = NycTlcYellow(start_date=start_date, end_date=end_date)\n",
							"nyc_tlc_df = nyc_tlc.to_spark_dataframe()"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"source": [
							"#To make development easier, faster and less expensive downsample for now\n",
							"sampled_taxi_df = nyc_tlc_df.sample(True, 0.001, seed=1234)"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Exploratory Data Analysis\n",
							"\n",
							"Look at the data and evaluate its suitability for use in a model, do this via some basic charts focussed on tip values and relationships."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"#The charting package needs a Pandas dataframe or numpy array do the conversion\n",
							"sampled_taxi_pd_df = sampled_taxi_df.toPandas()\n",
							"\n",
							"# Look at tips by amount count histogram\n",
							"ax1 = sampled_taxi_pd_df['tipAmount'].plot(kind='hist', bins=25, facecolor='lightblue')\n",
							"ax1.set_title('Tip amount distribution')\n",
							"ax1.set_xlabel('Tip Amount ($)')\n",
							"ax1.set_ylabel('Counts')\n",
							"plt.suptitle('')\n",
							"plt.show()\n",
							"\n",
							"# How many passengers tip'd by various amounts\n",
							"ax2 = sampled_taxi_pd_df.boxplot(column=['tipAmount'], by=['passengerCount'])\n",
							"ax2.set_title('Tip amount by Passenger count')\n",
							"ax2.set_xlabel('Passenger count') \n",
							"ax2.set_ylabel('Tip Amount ($)')\n",
							"plt.suptitle('')\n",
							"plt.show()\n",
							"\n",
							"# Look at the relationship between fare and tip amounts\n",
							"ax = sampled_taxi_pd_df.plot(kind='scatter', x= 'fareAmount', y = 'tipAmount', c='blue', alpha = 0.10, s=2.5*(sampled_taxi_pd_df['passengerCount']))\n",
							"ax.set_title('Tip amount by Fare amount')\n",
							"ax.set_xlabel('Fare Amount ($)')\n",
							"ax.set_ylabel('Tip Amount ($)')\n",
							"plt.axis([-2, 80, -2, 20])\n",
							"plt.suptitle('')\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Data Prep and Featurization\n",
							"\n",
							"It's clear from the visualizations above that there are a bunch of outliers in the data. These will need to be filtered out in addition there are extra variables that are not going to be useful in the model we build at the end.\n",
							"\n",
							"Finally there is a need to create some new (derived) variables that will work better with the model.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"taxi_df = sampled_taxi_df.select('totalAmount', 'fareAmount', 'tipAmount', 'paymentType', 'rateCodeId', 'passengerCount'\\\n",
							"                                , 'tripDistance', 'tpepPickupDateTime', 'tpepDropoffDateTime'\\\n",
							"                                , date_format('tpepPickupDateTime', 'hh').alias('pickupHour')\\\n",
							"                                , date_format('tpepPickupDateTime', 'EEEE').alias('weekdayString')\\\n",
							"                                , (unix_timestamp(col('tpepDropoffDateTime')) - unix_timestamp(col('tpepPickupDateTime'))).alias('tripTimeSecs')\\\n",
							"                                , (when(col('tipAmount') > 0, 1).otherwise(0)).alias('tipped')\n",
							"                                )\\\n",
							"                        .filter((sampled_taxi_df.passengerCount > 0) & (sampled_taxi_df.passengerCount < 8)\\\n",
							"                                & (sampled_taxi_df.tipAmount >= 0) & (sampled_taxi_df.tipAmount <= 25)\\\n",
							"                                & (sampled_taxi_df.fareAmount >= 1) & (sampled_taxi_df.fareAmount <= 250)\\\n",
							"                                & (sampled_taxi_df.tipAmount < sampled_taxi_df.fareAmount)\\\n",
							"                                & (sampled_taxi_df.tripDistance > 0) & (sampled_taxi_df.tripDistance <= 100)\\\n",
							"                                & (sampled_taxi_df.rateCodeId <= 5)\n",
							"                                & (sampled_taxi_df.paymentType.isin({\"1\", \"2\"}))\n",
							"                                )"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Data Prep and Featurization Part 2\n",
							"\n",
							"Having created new variables its now possible to drop the columns they were derived from so that the dataframe that goes into the model is the smallest in terms of number of variables, that is required.\n",
							"\n",
							"Also create some more features based on new columns from the first round.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"taxi_featurised_df = taxi_df.select('totalAmount', 'fareAmount', 'tipAmount', 'paymentType', 'passengerCount'\\\n",
							"                                                , 'tripDistance', 'weekdayString', 'pickupHour','tripTimeSecs','tipped'\\\n",
							"                                                , when((taxi_df.pickupHour <= 6) | (taxi_df.pickupHour >= 20),\"Night\")\\\n",
							"                                                .when((taxi_df.pickupHour >= 7) & (taxi_df.pickupHour <= 10), \"AMRush\")\\\n",
							"                                                .when((taxi_df.pickupHour >= 11) & (taxi_df.pickupHour <= 15), \"Afternoon\")\\\n",
							"                                                .when((taxi_df.pickupHour >= 16) & (taxi_df.pickupHour <= 19), \"PMRush\")\\\n",
							"                                                .otherwise(0).alias('trafficTimeBins')\n",
							"                                              )\\\n",
							"                                       .filter((taxi_df.tripTimeSecs >= 30) & (taxi_df.tripTimeSecs <= 7200))"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Encoding\n",
							"\n",
							"Different ML algorithms support different types of input, for this example Logistic Regression is being used for Binary Classification. This means that any Categorical (string) variables must be converted to numbers.\n",
							"\n",
							"The process is not as simple as a \"map\" style function as the relationship between the numbers can introduce a bias in the resulting model, the approach is to index the variable and then encode using a std approach called One Hot Encoding.\n",
							"\n",
							"This approach requires the encoder to \"learn\"/fit a model over the data in the Spark instance and then transform based on what was learnt.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# The sample uses an algorithm that only works with numeric features convert them so they can be consumed\n",
							"sI1 = StringIndexer(inputCol=\"trafficTimeBins\", outputCol=\"trafficTimeBinsIndex\"); \n",
							"en1 = OneHotEncoder(dropLast=False, inputCol=\"trafficTimeBinsIndex\", outputCol=\"trafficTimeBinsVec\");\n",
							"sI2 = StringIndexer(inputCol=\"weekdayString\", outputCol=\"weekdayIndex\"); \n",
							"en2 = OneHotEncoder(dropLast=False, inputCol=\"weekdayIndex\", outputCol=\"weekdayVec\");\n",
							"\n",
							"# Create a new dataframe that has had the encodings applied\n",
							"encoded_final_df = Pipeline(stages=[sI1, en1, sI2, en2]).fit(taxi_featurised_df).transform(taxi_featurised_df)"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Generation of Testing and Training Data Sets\n",
							"Simple split, 70% for training and 30% for testing the model. Playing with this ratio may result in different models.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# Decide on the split between training and testing data from the dataframe \n",
							"trainingFraction = 0.7\n",
							"testingFraction = (1-trainingFraction)\n",
							"seed = 1234\n",
							"\n",
							"# Split the dataframe into test and training dataframes\n",
							"train_data_df, test_data_df = encoded_final_df.randomSplit([trainingFraction, testingFraction], seed=seed)"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Train the Model\n",
							"\n",
							"Train the Logistic Regression model and then evaluate it using Area under ROC as the metric."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"## Create a new LR object for the model\n",
							"logReg = LogisticRegression(maxIter=10, regParam=0.3, labelCol = 'tipped')\n",
							"\n",
							"## The formula for the model\n",
							"classFormula = RFormula(formula=\"tipped ~ pickupHour + weekdayVec + passengerCount + tripTimeSecs + tripDistance + fareAmount + paymentType+ trafficTimeBinsVec\")\n",
							"\n",
							"## Undertake training and create an LR model\n",
							"lrModel = Pipeline(stages=[classFormula, logReg]).fit(train_data_df)\n",
							"\n",
							"## Saving the model is optional but its another for of inter session cache\n",
							"datestamp = datetime.now().strftime('%m-%d-%Y-%s');\n",
							"fileName = \"lrModel_\" + datestamp;\n",
							"logRegDirfilename = fileName;\n",
							"lrModel.save(logRegDirfilename)\n",
							"\n",
							"## Predict tip 1/0 (yes/no) on the test dataset, evaluation using AUROC\n",
							"predictions = lrModel.transform(test_data_df)\n",
							"predictionAndLabels = predictions.select(\"label\",\"prediction\").rdd\n",
							"metrics = BinaryClassificationMetrics(predictionAndLabels)\n",
							"print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Evaluate and Visualize\n",
							"\n",
							"Plot the actual curve to develop a better understanding of the model.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"## Plot the ROC curve, no need for pandas as this uses the modelSummary object\n",
							"modelSummary = lrModel.stages[-1].summary\n",
							"\n",
							"plt.plot([0, 1], [0, 1], 'r--')\n",
							"plt.plot(modelSummary.roc.select('FPR').collect(),\n",
							"         modelSummary.roc.select('TPR').collect())\n",
							"plt.xlabel('False Positive Rate')\n",
							"plt.ylabel('True Positive Rate')\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 10
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Load to DataFrame')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ws1sparkpool1",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/edf6dd9d-7c4a-4bca-a997-945f3d60cf4e/resourceGroups/rg-poc-test/providers/Microsoft.Synapse/workspaces/ajmnugiqxczz6x2pocws1/bigDataPools/ws1sparkpool1",
						"name": "ws1sparkpool1",
						"type": "Spark",
						"endpoint": "https://ajmnugiqxczz6x2pocws1.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ws1sparkpool1",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 5,
						"cores": 8,
						"memory": 56
					}
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"from azureml.opendatasets import NycTlcYellow\n",
							"\n",
							"data = NycTlcYellow()\n",
							"df = data.to_spark_dataframe()\n",
							"# Display 10 rows\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook 1')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					}
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://public@ajmnugiqxczz6x2poc.dfs.core.windows.net/fares-data.csv', format='csv'\r\n",
							"## Ifheaderexistsuncommentlinebelow\r\n",
							"##, header=True\r\n",
							")\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sparkTable')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ws1sparkpool1",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/edf6dd9d-7c4a-4bca-a997-945f3d60cf4e/resourceGroups/rg-poc-test/providers/Microsoft.Synapse/workspaces/ajmnugiqxczz6x2pocws1/bigDataPools/ws1sparkpool1",
						"name": "ws1sparkpool1",
						"type": "Spark",
						"endpoint": "https://ajmnugiqxczz6x2pocws1.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ws1sparkpool1",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 5,
						"cores": 8,
						"memory": 56
					}
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"outputs_hidden": true
							}
						},
						"source": [
							"from azureml.opendatasets import NycTlcYellow\n",
							"\n",
							"data = NycTlcYellow()\n",
							"df = data.to_spark_dataframe()\n",
							"# Display 10 rows\n",
							"df.write.mode(\"overwrite\").saveAsTable(\"default.nyc_yellow_taxi\")"
						],
						"outputs": [],
						"execution_count": 1
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ajmnugiqxczz6x2pocws1p1')]",
			"type": "Microsoft.Synapse/workspaces/sqlPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"collation": "SQL_Latin1_General_CP1_CI_AS",
				"maxSizeBytes": 263882790666240,
				"restorePointInTime": "0001-01-01T00:00:00",
				"annotations": []
			},
			"dependsOn": [],
			"location": "westus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SampleSQL')]",
			"type": "Microsoft.Synapse/workspaces/sqlPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"collation": "SQL_Latin1_General_CP1_CI_AS",
				"maxSizeBytes": 263882790666240,
				"restorePointInTime": "0001-01-01T00:00:00",
				"annotations": []
			},
			"dependsOn": [],
			"location": "westus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/default')]",
			"type": "Microsoft.Synapse/workspaces/managedVirtualNetworks",
			"apiVersion": "2019-06-01-preview",
			"properties": {},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/default/managedPrivateEndpoint1')]",
			"type": "Microsoft.Synapse/workspaces/managedVirtualNetworks/managedPrivateEndpoints",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"privateLinkResourceId": "/subscriptions/edf6dd9d-7c4a-4bca-a997-945f3d60cf4e/resourceGroups/rg-poc-test/providers/Microsoft.Storage/storageAccounts/ajmnugiqxczz6x2poc",
				"groupId": "dfs"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/managedVirtualNetworks/default')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Scoring machine learning models in dedicated SQL pool')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "/* This is a sample script for loading and scoring machine learning models using New York taxi data.\n   The query scenario is to predict the fare for taking a trip around New York City.\n   First, create two tables: to store the sample machine learning model and scoring data.\n   Next, load the data and the model in their respective tables.\n   Last, use T-SQL Predict to score the model.\n   Run the script below to see the results.\n*/\n\n-- Create a table to store the model.\nCREATE TABLE [dbo].[AllModels]\n(\n    [Model] [varbinary](max) NULL\n)\nWITH\n(\n    DISTRIBUTION = ROUND_ROBIN,\n    HEAP\n)\nGO\n\n-- Next, load the hexadecimal string of the model from Azure Data Lake storage location into the table.\nCOPY INTO [AllModels] (Model)\nFROM 'https://nytaxiblob.blob.core.windows.net/samplepredictdata/NYC-fare-prediction.onnx.hex'\nWITH (\n    FILE_TYPE = 'CSV'\n)\n\n-- Create a table to store the sample scoring data.\nCREATE TABLE [dbo].[TaxiTrips]\n(\n\t[vendorID] [real] NOT NULL,\n\t[passengerCount] [real] NULL,\n\t[tripDistance] [real] NULL,\n\t[month_num] [real] NULL,\n\t[day_of_month] [real] NULL,\n\t[day_of_week] [real] NULL,\n\t[day_of_hour] [real] NULL\n)\nWITH\n(\n\tDISTRIBUTION = ROUND_ROBIN,\n\tHEAP\n)\nGO\n\n-- Next, load the sample data from the Azure Data Lake location.\nCOPY INTO [dbo].[TaxiTrips] (vendorID, passengerCount, tripDistance, month_num, day_of_month, day_of_week, day_of_hour)\nFROM 'https://nytaxiblob.blob.core.windows.net/samplepredictdata/tripstestdata.csv'\nWITH (\n    FILE_TYPE = 'CSV',\n\tFIRSTROW = 2,\n    FIELDTERMINATOR=',',\n    ROWTERMINATOR='0x0A'\n\t)\n\n-- Use Predict find out what the fare of various trips around New York City is.\n-- A new column is generated called totalAmount with data type float that will contain the predicted amount.\nSELECT [vendorID],\n \t   [passengerCount],\n\t   [tripDistance],\n\t   [month_num],\n\t   [day_of_month],\n\t   [day_of_week],\n\t   [day_of_hour],\n\t   [totalAmount]\nFROM PREDICT (model = (SELECT Model FROM AllModels), Data = dbo.TaxiTrips, RUNTIME=ONNX) WITH (totalAmount float)\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"poolName": "SampleSQL",
						"databaseName": "SampleSQL"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Dynamic Data Masking for dedicated SQL pools')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "DROP TABLE Membership;\n\nCREATE TABLE Membership\n(MemberID int IDENTITY,\n FirstName varchar(100) MASKED WITH (FUNCTION = 'partial(1,\"XXXXXXX\",0)') NULL,\n LastName varchar(100) NOT NULL,\n Phone varchar(12) MASKED WITH (FUNCTION = 'default()') NULL,\n Email varchar(100) MASKED WITH (FUNCTION = 'email()') NULL);\n\n--Insert sample data in the table\nINSERT Membership VALUES ('Roberto', 'Tamburello', '555.123.4567', 'RTamburello@contoso.com');\nINSERT Membership VALUES ('Janice', 'Galvin', '555.123.4568', 'JGalvin@contoso.com.co');\nINSERT Membership VALUES ('Zheng', 'Mu', '555.123.4569', 'ZMu@contoso.net');\nSELECT * FROM Membership;\n\n--A new user is created and granted SELECT permission on the table. Queries executed as the TestUser view masked data.\n\nDROP USER TestUser;\n\nCREATE USER TestUser WITHOUT LOGIN;\nGRANT SELECT ON Membership TO TestUser;\n\n--Test user permissions\nEXECUTE AS USER = 'TestUser';\nSELECT * FROM Membership;\nREVERT;\n\n--The following example adds a masking function to the LastName column\nALTER TABLE Membership\nALTER COLUMN LastName ADD MASKED WITH (FUNCTION = 'partial(2,\"XXX\",0)');\n\n--The following example changes a masking function on the LastName column\nALTER TABLE Membership\nALTER COLUMN LastName varchar(100) MASKED WITH (FUNCTION = 'default()');\n\n--Granting the UNMASK permission allows TestUser to see the data unmasked\nGRANT UNMASK TO TestUser;\nEXECUTE AS USER = 'TestUser';\nSELECT * FROM Membership;\nREVERT;\n\n-- Removing the UNMASK permission\nREVOKE UNMASK TO TestUser;\n\n--The following statement drops the mask on the LastName column created in the previous example\nALTER TABLE Membership\nALTER COLUMN LastName DROP MASKED;\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"poolName": "SampleSQL",
						"databaseName": "SampleSQL"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 2')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT TOP (100) [MemberID]\n,[FirstName]\n,[LastName]\n,[Phone]\n,[Email]\n FROM [dbo].[Membership]",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"poolName": "SampleSQL",
						"databaseName": "SampleSQL"
					}
				}
			},
			"dependsOn": []
		}
	]
}